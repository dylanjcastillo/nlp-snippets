{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and define sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text(sample, clean):\n",
    "    print(f\"Before: {sample}\")\n",
    "    print(f\"After: {clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: This is a SAMPLE TEXT\n",
      "After: this is a sample text\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This is a SAMPLE TEXT\"\n",
    "clean_text = sample_text.lower()\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove cases (useful for comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: This is a SAMPLE TEXT\n",
      "After: this is a sample text\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This is a SAMPLE TEXT\"\n",
    "clean_text = sample_text.casefold()\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Some URLs: https://example.com http://example.io http://exam-ple.com More text\n",
      "After: Some URLs:    More text\n"
     ]
    }
   ],
   "source": [
    "# Source: https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/40823105#40823105\n",
    "sample_text = \"Some URLs: https://example.com http://example.io http://exam-ple.com More text\"\n",
    "clean_text = re.sub(r\"https?://\\S+\", \"\", sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove a tags but keep content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Here's <a href='https://example.com'> a tag</a>\n",
      "After: Here's  a tag\n"
     ]
    }
   ],
   "source": [
    "# Source: https://stackoverflow.com/questions/20867719/removing-a-href-tag-using-regex\n",
    "sample_text = \"Here's <a href='https://example.com'> a tag</a>\"\n",
    "clean_text = re.sub(r\"<a[^>]*>(.*?)</a>\", r\"\\1\", sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove multiple spaces, tabs, and indents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \t\tA      text\t\t\t\n",
      "\n",
      " Example\n",
      "After: A text Example\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\\t\\tA      text\\t\\t\\t\\n\\n Example\"\n",
    "clean_text = \" \".join(sample_text.split())\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: A lot of !!!! .... ,,,, ;;;;;;;?????\n",
      "After: A lot of    \n"
     ]
    }
   ],
   "source": [
    "sample_text = \"A lot of !!!! .... ,,,, ;;;;;;;?????\"\n",
    "clean_text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: This are some numbers: 1919191 2229292 11.233 22/22/22. Don't remove this one H2O\n",
      "After: This are some numbers: .//. Don't remove this one H2O\n"
     ]
    }
   ],
   "source": [
    "# Source: https://stackoverflow.com/questions/40020326/how-to-remove-words-containing-only-numbers-in-python\n",
    "sample_text = \"This are some numbers: 1919191 2229292 11.233 22/22/22. Don't remove this one H2O\"\n",
    "clean_text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: I want to keep this one: 10/10/20 but not this one 222333\n",
      "After: I want to keep this one: 10/10/20 but not this one \n"
     ]
    }
   ],
   "source": [
    "sample_text = \"I want to keep this one: 10/10/20 but not this one 222333\"\n",
    "clean_text = \" \".join([\"\" if w.isdigit() else w for w in sample_text.split()])\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Sample text 123 !!!! Haha.... !!!! ##$$$%%%%\n",
      "After: Sample text 123  Haha  \n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Sample text 123 !!!! Haha.... !!!! ##$$$%%%%\"\n",
    "clean_text = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: this is a sample text\n",
      "After: this sample text\n"
     ]
    }
   ],
   "source": [
    "stop_words = [\"is\", \"a\"]\n",
    "sample_text = \"this is a sample text\"\n",
    "tokens = sample_text.split()\n",
    "clean_tokens = [t for t in tokens if not t in stop_words]\n",
    "clean_text = \" \".join(clean_tokens)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove short tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: this is a sample text. I'll remove the a\n",
      "After: this is sample text. I'll remove the\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"this is a sample text. I'll remove the a\"\n",
    "tokens = sample_text.split()\n",
    "clean_tokens = [t for t in tokens if len(t) > 1]\n",
    "clean_text = \" \".join(clean_tokens)\n",
    "print_text(sample_text, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: this is a text ready to tokenize\n",
      "After: ['this', 'is', 'a', 'text', 'ready', 'to', 'tokenize']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "sample_text = \"this is a text ready to tokenize\"\n",
    "clean_text = word_tokenize(sample_text)\n",
    "print_text(sample_text, clean_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
